---
title: 21st Workshop on Innovative Use of NLP for Building Educational Applications
permalink: /bea/2026
redirect_from: /bea/21
sidebar:
  nav: "bea21"
toc: true
toc_sticky: true
toc_icon: 'cog'
---

![Grand Hyatt Manchester San Diego](/assets/images/venues/san-diego-grand-hyatt-manchester.jpg)

| Quick Info          |                |
|---------------------|---------------------|
| **Co-located with** | [ACL 2026](https://2026.aclweb.org/) |
| **Location**        | San Diego, California, United States |
| **Dates**           | July 2-3, 2026 |
| **Organizers**      | Ekaterina Kochmar, Bashar Alhafni, Stefano Bannò, Marie Bexte, Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante, Anaïs Tack, Victoria Yaneva, Zheng Yuan |
| **Contact**         | [bea.nlp.workshop@gmail.com](mailto:bea.nlp.workshop@gmail.com) |
| **GitHub**          | To share your code and data with the BEA community, feel free to use the [#bea-workshop](https://github.com/topics/bea-workshop) topic. |

## Description

The **BEA Workshop** is a leading venue for NLP innovation in the context of educational applications.
It is one of the largest one-day workshops in the ACL community with over 100 registered attendees in the past several years.
The growing interest in educational applications and a diverse community of researchers involved resulted in the creation of the [Special Interest Group in Educational Applications (SIGEDU)](https://www.aclweb.org/adminwiki/index.php?title=2019Q3_Reports:_SIGEDU) in 2017, which currently has over 400 members.

The **workshop's continuing growth** reflects how technology is increasingly fulfilling societal demands.
For instance, the BEA16 workshop in 2021 hosted a panel discussion on "New Challenges for Educational Technology in the Time of the Pandemic" addressing the pressing issues around COVID-19.
Additionally, NLP has evolved to aid diverse learning domains, including writing, speaking, reading, science, and mathematics, as well as the related intra-personal (e.g., self-confidence) and inter-personal (e.g., peer collaboration) skills.
Within these areas, the community continues to develop and deploy innovative NLP approaches for use in educational settings.

Another significant advancement in educational applications within the Computational Linguistics (CL) community is the **continuing series of shared-task competitions** organized by and hosted at the BEA workshop.
Over the years, this initiative has included four dedicated tasks focused solely on grammatical error detection and correction (with the latest one on [Grammatical Error Correction](https://www.cl.cam.ac.uk/research/nl/bea2019st/) held in 2019.
Moreover, NLP/Education shared tasks have expanded into novel research areas, such as [Automated Evaluation of Scientific Writing](/sharedtask/2016) in 2016, [Native Language Identification](/sharedtask/2017) in 2017, [Second Language Acquisition Modeling](/sharedtask/2018-SLAM) and [Complex Word Identification](/sharedtask/2018-CWI) in 2018, [Generating AI Teacher Responses in Educational Dialogues](/sharedtask/2023) in 2023, [Automated Prediction of Item Difficulty and Item Response Time](https://sig-edu.org/sharedtask/2024) and [Multilingual Lexical Simplification](https://sites.google.com/view/mlsp-sharedtask-2024) in 2024, and [Pedagogical Ability Assessment of AI-powered Tutors](https://sig-edu.org/sharedtask/2025) in 2025.
These competitions have significantly bolstered the visibility and interest in our field.

The **21st BEA** will be a **2-day workshop**, with one in-person workshop day and one virtual workshop day. The workshop will feature **oral presentation sessions** and **large poster sessions** to facilitate the presentation of a wide array of original research. Moreover, there will be **a panel discussion** on *Academic and industry perspectives on the use of generative AI in education: opportunities and challenges*, **a half-day tutorial** on *Theory of Mind and its Applications in Educational Contexts*, and **two shared tasks** on *[Vocabulary Difficulty Prediction for English Learners](https://www.britishcouncil.org/data-science-and-insights/bea2026st)* and on *Rubric-based Short Answer Scoring for German* comprising an oral *overview presentation* by the shared task organizers and several *poster presentations* by the shared task participants.

## Call for Papers

The workshop invites submissions to the **main track**, including both long and short papers. Accepted submissions will be considered for oral or poster presentations.

Topics of interest include, but are not limited to, the application of NLP techniques in educational settings such as:
- automated evaluation of written and spoken open-ended responses
- game-based learning and assessment methods
- educational data mining
- exploring the role and impact of generative AI in education
- intelligent tutoring systems
- collaborative and social learning platforms
- peer assessment and review tools
- grammar error detection and correction
- learner cognition modeling
- spoken dialogue systems
- multimodal educational applications
- annotation standards and linguistic schemas
- tools for teachers, learners, and assessment developers
- corpus-based educational tools and systems

Submissions will be open soon.

### Important Dates

All deadlines are 11:59pm UTC-12 (anywhere on earth). Please note that these deadlines are preliminary and may change slightly.
{: .notice--danger}

| Event                         | Date                |
|-------------------------------|---------------------|
| Submission Deadline           | March 5, 2026      |
| Notification of Acceptance    | April 28, 2026      |
| Camera-ready Papers Due       | May 12, 2026      |
| Pre-recorded Videos Due       | June 4, 2026         |
| Workshop                      | July 2-3, 2026 |


## Shared Tasks

We will host two shared tasks:

### Vocabulary Difficulty Prediction for English Learners

**Organizers:** Mariano Felice (British Council) and Lucy Skidmore (British Council).
{: .notice}

**Description:** This shared task aims to advance research into vocabulary difficulty prediction for learners of English with diverse L1 backgrounds, an essential step towards custom content creation, computer-adaptive testing and personalised learning. In a context where traditional item calibration methods have become a bottleneck for the implementation of digital learning and assessment systems, we believe predictive NLP models can provide a more scalable, cost-effective solution. The goal of this shared task is to build regression models to predict the difficulty of English words given a learner's L1. We believe this new shared task provides a novel approach to vocabulary modelling, offering a multidimensional perspective that has not been explored in previous work. To this aim, we will use the British Council's Knowledge-based Vocabulary Lists (KVL), a multilingual dataset with psychometrically calibrated difficulty scores. We believe this unique dataset is not only an invaluable contribution to the NLP community but also a powerful resource that will enable in-depth investigations into how linguistic features, L1 background and contextual cues influence vocabulary difficulty. 
{: .notice--primary}

For more information on how to participate and latest updates, please refer to the [shared task website](https://www.britishcouncil.org/data-science-and-insights/bea2026st).

### Rubric-based Short Answer Scoring for German

**Organizers:** Sebastian Gombert (DIPF), Zhifan Sun (DIPF), Fabian Zehner (DIPF), Jannik Lossjew (IPN), Tobias Wyrwich (IPN), Berrit Katharina Czinczel (IPN), David Bednorz (IPN), Sascha Bernholt (IPN), Knut Neumann (IPN), Ute Harms (IPN), Aiso Heinze (IPN), and Hendrik Drachsler (DIPF)
{: .notice}

**Description:** Short answer scoring is a well-established task in educational natural language processing. In this shared task, we introduce and focus on **rubric-based short-answer scoring**, a task formulation in which models are provided with a question, a student answer, and a textual scoring rubric that specifies criteria for each possible score level. Successfully solving this task requires models to interpret the semantics of scoring rubrics and apply their criteria to previously unseen answers, closely mirroring how human raters assign scores in educational assessment. Although rubrics have been used as auxiliary information in prior work on free-text scoring and LLM-based approaches, there has been little focused investigation of rubric-based short-answer scoring as a task in its own right. This setting poses distinct challenges, including ambiguous or underspecified rubric criteria and a wide range of valid student responses. With this shared task, we aim to stimulate systematic research on rubric-based scoring, assess how well current NLP methods can reason over rubrics, and identify promising modeling strategies. Additionally, by providing a German-language dataset, the shared task contributes a new non-English benchmark to the field. 
{: .notice--primary}

For more information on how to participate and latest updates, please refer to the [shared task website](https://edutec.science/bea-2026-shared-task/).



## Tutorial

We will also host a half-day tutorial:

### Theory of Mind and Application in Educational Context

**Organizers:** Effat Farhana (Auburn University), Maha Zainab (Auburn University), Qiaosi Wang (Carnegie Mellon University), Niloofar Mireshghallah (Carnegie Mellon University), Ramira van der Meulen (Leiden University), Max van Duijn (Leiden University).
{: .notice}

**Description:** This tutorial examines the integration of Theory of Mind (ToM) into AI-driven online tutoring systems, focusing on how advanced technologies, such as Large Language Models (LLMs), can model learners' cognitive and emotional states to provide adaptive, personalized feedback. Participants will learn foundational principles of ToM from cognitive science and psychology and how these concepts can be operationalized in AI systems. We will discuss mutual ToM, where both AI tutors and learners maintain models of each other's mental states, and address challenges such as detecting learner misconceptions, modeling meta-cognition, and maintaining privacy in data-driven tutoring. The tutorial also presents hands-on demonstrations of Machine ToM applied to programming education using datasets such as CS1QA and CodeQA, which contain Java and Python samples. By combining conceptual foundations, research insights, and practical exercises, this tutorial provides a comprehensive overview of designing human-centered, ethically aware, and cognitively informed AI tutoring systems.
{: .notice--primary}


## Committees

### Organizing Committee

- **General Chair**: [Ekaterina Kochmar](https://ekochmar.github.io/about/), MBZUAI
- **Program Chairs**:
  - [Andrea Horbach](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/andrea.horbach.shtml), Hildesheim University
  - [Ronja Laarmann-Quante](https://www.ltl.uni-due.de/team/ronja-laarmann-quante), Ruhr University Bochum
  - [Marie Bexte](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/marie.bexte.shtml), FernUniversität in Hagen
- **Publication Chair**: [Anaïs Tack](https://anaistack.github.io/), KU Leuven, imec
- **Shared Task & Tutorial Chairs**:
  - [Victoria Yaneva](http://www.victoriayaneva.info/), National Board of Medical Examiners
  - [Bashar Alhafni](https://www.basharalhafni.com), MBZUAI
- **Sponsorship Chair**:
  - [Zheng Yuan](https://www.cl.cam.ac.uk/~zy249/), King's College London
  - [Jill Burstein](https://sites.google.com/site/jbursteinets/), Duolingo
- **Virtual Chair**: Stefano Bannò, Cambridge University
