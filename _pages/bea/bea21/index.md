---
title: 21st Workshop on Innovative Use of NLP for Building Educational Applications
permalink: /bea/2026
redirect_from: /bea/21
sidebar:
  nav: "bea21"
toc: true
toc_sticky: true
toc_icon: 'cog'
---

![Grand Hyatt Manchester San Diego](/assets/images/venues/san-diego-grand-hyatt-manchester.jpg)

| Quick Info          |                |
|---------------------|---------------------|
| **Co-located with** | [ACL 2026](https://2026.aclweb.org/) |
| **Location**        | San Diego, California, United States |
| **Dates**           | July 2-3, 2026 |
| **Organizers**      | Ekaterina Kochmar, Bashar Alhafni, Stefano Bannò, Marie Bexte, Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante, Anaïs Tack, Victoria Yaneva, Zheng Yuan |
| **Submission**         | [https://softconf.com/acl2026/bea2026/](https://softconf.com/acl2026/bea2026/) |
| **Contact**         | [bea.nlp.workshop@gmail.com](mailto:bea.nlp.workshop@gmail.com) |
| **GitHub**          | To share your code and data with the BEA community, feel free to use the [#bea-workshop](https://github.com/topics/bea-workshop) topic. |

## Description

The **BEA Workshop** is a leading venue for NLP innovation in the context of educational applications.
It is one of the largest one-day workshops in the ACL community with over 100 registered attendees in the past several years.
The growing interest in educational applications and a diverse community of researchers involved resulted in the creation of the [Special Interest Group in Educational Applications (SIGEDU)](https://www.aclweb.org/adminwiki/index.php?title=2019Q3_Reports:_SIGEDU) in 2017, which currently has over 400 members.

The **workshop's continuing growth** reflects how technology is increasingly fulfilling societal demands.
For instance, the BEA16 workshop in 2021 hosted a panel discussion on "New Challenges for Educational Technology in the Time of the Pandemic" addressing the pressing issues around COVID-19.
Additionally, NLP has evolved to aid diverse learning domains, including writing, speaking, reading, science, and mathematics, as well as the related intra-personal (e.g., self-confidence) and inter-personal (e.g., peer collaboration) skills.
Within these areas, the community continues to develop and deploy innovative NLP approaches for use in educational settings.

Another significant advancement in educational applications within the Computational Linguistics (CL) community is the **continuing series of shared-task competitions** organized by and hosted at the BEA workshop.
Over the years, this initiative has included four dedicated tasks focused solely on grammatical error detection and correction (with the latest one on [Grammatical Error Correction](https://www.cl.cam.ac.uk/research/nl/bea2019st/) held in 2019.
Moreover, NLP/Education shared tasks have expanded into novel research areas, such as [Automated Evaluation of Scientific Writing](/sharedtask/2016) in 2016, [Native Language Identification](/sharedtask/2017) in 2017, [Second Language Acquisition Modeling](/sharedtask/2018-SLAM) and [Complex Word Identification](/sharedtask/2018-CWI) in 2018, [Generating AI Teacher Responses in Educational Dialogues](/sharedtask/2023) in 2023, [Automated Prediction of Item Difficulty and Item Response Time](https://sig-edu.org/sharedtask/2024) and [Multilingual Lexical Simplification](https://sites.google.com/view/mlsp-sharedtask-2024) in 2024, and [Pedagogical Ability Assessment of AI-powered Tutors](https://sig-edu.org/sharedtask/2025) in 2025.
These competitions have significantly bolstered the visibility and interest in our field.

The **21st BEA** will be a **2-day workshop**, with one in-person workshop day and one virtual workshop day. The workshop will feature **oral presentation sessions** and **large poster sessions** to facilitate the presentation of a wide array of original research. Moreover, there will be **a panel discussion** on *Academic and industry perspectives on the use of generative AI in education: opportunities and challenges*, **a half-day tutorial** on *Theory of Mind and its Applications in Educational Contexts*, and **two shared tasks** on *[Vocabulary Difficulty Prediction for English Learners](https://www.britishcouncil.org/data-science-and-insights/bea2026st)* and on *Rubric-based Short Answer Scoring for German* comprising an oral *overview presentation* by the shared task organizers and several *poster presentations* by the shared task participants.

## Call for Papers

The workshop invites submissions to the **main track**, including both long and short papers. Accepted submissions will be considered for oral or poster presentations.

Topics of interest include, but are not limited to, the application of NLP techniques in educational settings such as:
- automated evaluation of written and spoken open-ended responses
- game-based learning and assessment methods
- educational data mining
- exploring the role and impact of generative AI in education
- intelligent tutoring systems
- collaborative and social learning platforms
- peer assessment and review tools
- grammar error detection and correction
- learner cognition modeling
- spoken dialogue systems
- multimodal educational applications
- annotation standards and linguistic schemas
- tools for teachers, learners, and assessment developers
- corpus-based educational tools and systems

Submissions will be open soon.

### Important Dates

All deadlines are 11:59pm UTC-12 (anywhere on earth). Please note that these deadlines are preliminary and may change slightly.
{: .notice--danger}

| Event                         | Date                |
|-------------------------------|---------------------|
| Submission Deadline           | March 23, 2026      |
| Notification of Acceptance    | April 28, 2026      |
| Camera-ready Papers Due       | May 12, 2026      |
| Pre-recorded Videos Due       | June 4, 2026         |
| Workshop                      | July 2-3, 2026 |


### Submission Guidelines

To streamline the submission process, we rely on the **ACL submission guidelines** and the **START conference system**, accessible at [https://softconf.com/acl2026/bea2026/](https://softconf.com/acl2026/bea2026/).
All submissions undergo review by the [program committee](#program-committee).

Long, Short, and Demo Papers
: Authors can choose to submit long papers (up to eight (8) pages) or short papers (up to four (4) pages), alongside unlimited references.
After peer review, all accepted papers will be allotted an additional page of content (up to nine for long papers, five for short papers), allowing authors to address reviewer comments.
Authors are strongly urged to present a live demonstration for papers that elaborate on systems.
If opting for this, authors should choose either "long paper + demo" or "short paper + demo" under the "Submission Category" on the submission page.

LaTeX and Word Templates
: Authors must ensure their paper submissions adhere to the general paper formatting guidelines for "*ACL" conferences, found [here](https://acl-org.github.io/ACLPUB/formatting.html), and use the **official ACL style templates**, downloadable [here](https://github.com/acl-org/acl-style-files).
Do not modify these style files or use templates intended for other conferences.
Submissions failing to meet required styles, including paper size, margin width, and font size restrictions, will be rejected without review.

Limitations
: Authors are required to discuss the limitations of their work in a dedicated section titled "Limitations".
This section should be included at the end of the paper, before the references, and it will not count toward the page limit.
This includes both, long and short papers.
Note, prior to the December 2023 cycle, this was optional.

Ethics Policy
: Authors are required to honour the ethical code set out in the [ACL Code of Ethics](https://www.aclweb.org/portal/content/acl-code-ethics).
The consideration of the ethical impact of our research, use of data, and potential applications of our work has always been an important consideration, and as artificial intelligence is becoming more mainstream, these issues are increasingly pertinent.
We ask that all authors read the code, and ensure that their work is conformant to this code.
Authors are encouraged to devote a section of their paper to concerns about the ethical impact of the work and to a discussion of broader impacts of the work, which will be taken into account in the review process.
This discussion may extend into a 5th page (short papers) or 9th page (long papers).

Anonymity
: In accordance with ACL policy, pre-prints are allowed. However, given the blind review process, it is still essential to ensure that papers themselves remain anonymous.
Authors should avoid self-references that disclose their identity (e.g., “We previously showed (Smith, 1991)”), opting instead for citations like “Smith previously showed (Smith, 1991)”.

Conflicts of Interest
: Authors are required to mark potential reviewers who have co-authored the paper, belong to the same research group or institution, or have had prior exposure to the paper, ensuring transparency in the review process.

Double Submissions
: We adhere to the official ACL double-submission policy.
If papers are submitted to both BEA and another conference or workshop, authors must specify the other event on the title page (as a footnote on the abstract).
Additionally, the title page should state that if the paper is accepted for presentation at BEA, it will be withdrawn from other conferences and workshops.

Republications
: Previously published papers will not be accepted.

## Shared Tasks

We will host two shared tasks:

### Vocabulary Difficulty Prediction for English Learners

**Organizers:** Mariano Felice (British Council) and Lucy Skidmore (British Council).
{: .notice}

**Description:** This shared task aims to advance research into vocabulary difficulty prediction for learners of English with diverse L1 backgrounds, an essential step towards custom content creation, computer-adaptive testing and personalised learning. In a context where traditional item calibration methods have become a bottleneck for the implementation of digital learning and assessment systems, we believe predictive NLP models can provide a more scalable, cost-effective solution. The goal of this shared task is to build regression models to predict the difficulty of English words given a learner's L1. We believe this new shared task provides a novel approach to vocabulary modelling, offering a multidimensional perspective that has not been explored in previous work. To this aim, we will use the British Council's Knowledge-based Vocabulary Lists (KVL), a multilingual dataset with psychometrically calibrated difficulty scores. We believe this unique dataset is not only an invaluable contribution to the NLP community but also a powerful resource that will enable in-depth investigations into how linguistic features, L1 background and contextual cues influence vocabulary difficulty. 
{: .notice--primary}

For more information on how to participate and latest updates, please refer to the [shared task website](https://www.britishcouncil.org/data-science-and-insights/bea2026st).

### Rubric-based Short Answer Scoring for German

**Organizers:** Sebastian Gombert (DIPF), Zhifan Sun (DIPF), Fabian Zehner (DIPF), Jannik Lossjew (IPN), Tobias Wyrwich (IPN), Berrit Katharina Czinczel (IPN), David Bednorz (IPN), Sascha Bernholt (IPN), Knut Neumann (IPN), Ute Harms (IPN), Aiso Heinze (IPN), and Hendrik Drachsler (DIPF)
{: .notice}

**Description:** Short answer scoring is a well-established task in educational natural language processing. In this shared task, we introduce and focus on **rubric-based short-answer scoring**, a task formulation in which models are provided with a question, a student answer, and a textual scoring rubric that specifies criteria for each possible score level. Successfully solving this task requires models to interpret the semantics of scoring rubrics and apply their criteria to previously unseen answers, closely mirroring how human raters assign scores in educational assessment. Although rubrics have been used as auxiliary information in prior work on free-text scoring and LLM-based approaches, there has been little focused investigation of rubric-based short-answer scoring as a task in its own right. This setting poses distinct challenges, including ambiguous or underspecified rubric criteria and a wide range of valid student responses. With this shared task, we aim to stimulate systematic research on rubric-based scoring, assess how well current NLP methods can reason over rubrics, and identify promising modeling strategies. Additionally, by providing a German-language dataset, the shared task contributes a new non-English benchmark to the field. 
{: .notice--primary}

For more information on how to participate and latest updates, please refer to the [shared task website](https://edutec.science/bea-2026-shared-task/).



## Tutorial

We will also host a half-day tutorial:

### Theory of Mind and Application in Educational Context

**Organizers:** Effat Farhana (Auburn University), Maha Zainab (Auburn University), Qiaosi Wang (Carnegie Mellon University), Niloofar Mireshghallah (Carnegie Mellon University), Ramira van der Meulen (Leiden University), Max van Duijn (Leiden University).
{: .notice}

**Description:** This tutorial examines the integration of Theory of Mind (ToM) into AI-driven online tutoring systems, focusing on how advanced technologies, such as Large Language Models (LLMs), can model learners' cognitive and emotional states to provide adaptive, personalized feedback. Participants will learn foundational principles of ToM from cognitive science and psychology and how these concepts can be operationalized in AI systems. We will discuss mutual ToM, where both AI tutors and learners maintain models of each other's mental states, and address challenges such as detecting learner misconceptions, modeling meta-cognition, and maintaining privacy in data-driven tutoring. The tutorial also presents hands-on demonstrations of Machine ToM applied to programming education using datasets such as CS1QA and CodeQA, which contain Java and Python samples. By combining conceptual foundations, research insights, and practical exercises, this tutorial provides a comprehensive overview of designing human-centered, ethically aware, and cognitively informed AI tutoring systems.
{: .notice--primary}

## Panel

We invite applications and nominations for panelists to participate in a **panel discussion on "Transitioning from Academia to the EdTech Industry."** This panel aims to share practical insights, career pathways, challenges, and lessons learned by individuals who have navigated (or actively support) the move from academic careers into industry roles within educational technology.

The panel will be of interest to graduate students, postdoctoral researchers, faculty, and academic staff considering or preparing for careers in EdTech startups, established companies, or industry research labs.

### Panel Focus
Panelists are expected to address topics such as:
- Motivation for transitioning from academia to EdTech
- Differences in culture, expectations, and impact between academia and industry
- Translating academic skills (research, teaching, publishing) to industry roles
- Career paths in EdTech (e.g., product, research, UX, data science, learning design)
- Advice for early-career researchers and faculty considering the transition

### Eligibility & Selection Criteria
Panelists will be selected based on the following criteria:
- Relevant Experience: Demonstrated experience transitioning from academia to the EdTech industry, or substantial experience hiring, mentoring, or collaborating with academics in EdTech roles.
- Diversity of Perspectives: We aim to assemble a panel with diverse backgrounds, career stages, roles (e.g., startup, large company, research-focused, product-focused), and identities.
- Ability to Communicate Insights Clearly: Willingness and ability to share candid, reflective, and actionable advice with an academic audience.
- Engagement with the BEA Community: Experience or interest in BEA-related research areas, education, NLP, or applied AI for learning is a plus.
- In-Person Attendance: Panelists must be able to attend the BEA 2026 workshop in person at the conference venue and actively participate in the live panel discussion and Q&A.

### How to Apply or Nominate
Interested individuals may apply directly or be nominated by others. Submissions should include:
- Name, affiliation, and current role
- A brief bio (150–200 words) highlighting relevant experience
- A short statement (100–150 words) describing what perspective you would bring to the panel
- Confirmation of ability to attend the workshop in person

### Important Dates
- Submission Deadline: April 1st, 2026
- Notification of Acceptance: May 1st, 2026
- Workshop Date: July 2nd or 3rd, 2026, San Diego (co-located with ACL)

We particularly encourage applications and nominations from individuals from underrepresented groups and non-traditional career paths.

For questions, please contact: [bea.nlp.workshop@gmail.com](mailto:bea.nlp.workshop@gmail.com)


## Committees

### Organizing Committee

- **General Chair**: [Ekaterina Kochmar](https://ekochmar.github.io/about/), MBZUAI
- **Program Chairs**:
  - [Andrea Horbach](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/andrea.horbach.shtml), Hildesheim University
  - [Ronja Laarmann-Quante](https://www.ltl.uni-due.de/team/ronja-laarmann-quante), Ruhr University Bochum
  - [Marie Bexte](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/marie.bexte.shtml), FernUniversität in Hagen
- **Publication Chair**: [Anaïs Tack](https://anaistack.github.io/), KU Leuven, imec
- **Shared Task & Tutorial Chairs**:
  - [Victoria Yaneva](http://www.victoriayaneva.info/), National Board of Medical Examiners
  - [Bashar Alhafni](https://www.basharalhafni.com), MBZUAI
- **Sponsorship Chair**:
  - [Zheng Yuan](https://www.cl.cam.ac.uk/~zy249/), King's College London
  - [Jill Burstein](https://sites.google.com/site/jbursteinets/), Duolingo
- **Virtual Chair**: Stefano Bannò, Cambridge University
